SWAHILI SCAM DETECTION PROJECT WORKFLOW AND Q&A GUIDE
This document explains how the project works end-to-end. All claims are grounded in specific files and functions in this project.
TERMINOLOGY AND SYNONYMS

Dataset/Data: Collection of Swahili messages labeled as scam (1) or legitimate (0)
Preprocessing: Text cleaning and normalization
Feature Engineering/Feature Extraction: Converting text into numerical patterns the computer can analyze
TF-IDF: Term Frequency-Inverse Document Frequency (measures word importance)
N-grams: Word sequences (1-gram = single word, 2-gram = word pairs)
BiLSTM: Bidirectional Long Short-Term Memory (a type of neural network)
BERT: Bidirectional Encoder Representations from Transformers (advanced language model)
Tokenization: Breaking text into individual words or subwords
Vocabulary/Vocab: Dictionary of all known words in the dataset
Model Training: Teaching the computer to recognize scam patterns
Evaluation: Testing how well the model performs on new messages
API: Application Programming Interface (web service for predictions)
Confidence Score: How certain the model is about its prediction (0-100%)
Traditional ML: Classical machine learning methods (Random Forest, SVM, etc.)
Neural Networks: AI models inspired by how the brain processes information

1. END-TO-END WORKFLOW (WHAT HAPPENS FROM DATA TO SERVING)
Data Source

File: data/raw/swahili_messages_sample.csv
Generated by: data/sample_data.py

create_sample_dataset() builds a labeled dataset (scam=1, legitimate=0) with categories and metadata
save_dataset(df) writes to data/raw/swahili_messages_sample.csv (UTF-8)



Preprocessing (applies across traditional ML and neural models)

File: src/swahili_preprocessor.py (class SwahiliPreprocessor)

clean_text(): lowercase; removes URLs, emails, phone numbers; normalizes whitespace
normalize_slang(): maps slang/variants to canonical terms using slang_dict
remove_stopwords(): removes curated Swahili stopwords (swahili_stopwords)
extract_basic_features(): counts scam/urgency/money/emotion signals, punctuation patterns, and language mix



Feature Engineering (traditional ML path)
What it does: Converts Swahili text messages into numerical data that traditional machine learning algorithms can understand and analyze.
File: src/feature_extractor.py (class SwahiliFeatureExtractor)
Two main approaches:

Statistical Text Analysis (TF-IDF):

Analyzes how frequently words appear in scam vs. legitimate messages
Looks at single words (1-grams) and word pairs (2-grams) like "piga simu" or "tuma pesa"
Identifies the 1000 most important word patterns that help distinguish scams
Example: Words like "hongera" (congratulations) appear more in scam messages


Custom Linguistic Features (Swahili-specific patterns):

Phone numbers: Counts how many phone numbers appear (scams often include contact numbers)
Money amounts: Detects mentions of money like "TSH 1,000,000" or "shilingi elfu"
Action words: Counts urgent commands like "piga" (call), "tuma" (send), "confirm"
Congratulatory words: Detects celebration terms like "hongera", "bahati", "ushindi" (winner)
Time pressure words: Identifies urgency like "sasa" (now), "haraka" (quickly), "urgent"



Output: Creates two files with numerical representations:

features.csv: Each message becomes a row of numbers representing all detected patterns
labels.csv: Corresponding scam (1) or legitimate (0) labels for training

Modeling (Teaching the computer to recognize scam patterns)
BiLSTM with Attention (primary deployed model)
What it is: A neural network that reads Swahili text like a human would - from left to right AND right to left simultaneously, paying special attention to important words.
File: src/bilstm_model.py
How it processes text:

Word Dictionary Creation: Builds a vocabulary of all unique Swahili words in the dataset, plus special tokens:

<PAD>: Fills empty spaces to make all messages the same length
<UNK>: Represents unknown words not seen during training
<START> and <END>: Mark message boundaries


Text to Numbers: Converts each Swahili word to a unique number the computer can process

The Neural Network Architecture:

Bidirectional LSTM: Reads messages in both directions to understand context better

Example: In "Piga simu sasa", it understands "piga" better by also knowing "sasa" comes later


Attention Mechanism: Focuses on the most important words for making decisions

Like highlighting key phrases: "hongera", "tuma pesa", "haraka"


Classification Head: Final layer that outputs scam probability (0-100%)

Training Process:

Smart Data Splitting: Ensures equal representation of scam/legitimate messages in training/testing
Learning Rate Adjustment: Automatically slows down learning when improvement plateaus
Gradient Clipping: Prevents the model from making too-large learning jumps
Early Stopping: Saves the best-performing version and stops when no more improvement
Model Checkpoint: Saves best model to models/bilstm_best_model.pth

Performance Measurement: Tests accuracy, precision (how many predicted scams are actually scams), recall (how many actual scams were caught), and F1 (balanced score)
BERT Fine-tuning (experimental alternative)
What it is: Uses Google's advanced multilingual language model, pre-trained on millions of texts, and specializes it for Swahili scam detection.
File: src/bert_model.py
Advantages:

Already understands many languages including Swahili
Can handle complex grammar and context better than BiLSTM
Uses subword tokenization (breaks words into meaningful parts)

Process:

Pre-trained Model: Starts with bert-base-multilingual-cased (Google's model)
Fine-tuning: Teaches this general model specifically about Swahili scam patterns
Tokenization: Automatically handles word variations and unknown words

Training: Uses Hugging Face's optimized training pipeline with the same evaluation metrics
Serving (Flask API + responsive web UI)
File: api/app.py

Model loading: load_model() → load_bilstm_model() (default), loads models/bilstm_best_model.pth and wraps it with a predict_proba interface
Endpoints:

GET / → responsive HTML interface (mobile-friendly) for manual testing
POST /api/predict → returns {is_scam, confidence, scam_probability, safe_probability, model_type}
GET /api/status → health and model status


Prediction flow (/api/predict):

If BiLSTM is loaded (default), text is preprocessed and converted to index sequences; model outputs class probabilities via softmax; confidence is the scam-class probability



2. SECTION 6.4 — BACKEND SYSTEM CODE (FLASK API) EXPLANATION
Overview: The entire api/app.py file (470 lines) serves as a complete web server that takes Swahili text messages and returns scam predictions. Think of it as a smart assistant that you can ask "Is this message a scam?" and it responds with a yes/no answer plus confidence level.
File Structure: api/app.py contains four main components:

System Initialization (Lines 1-21): Setting up the environment
AI Model Management (Lines 22-134): Loading and preparing different AI models
Prediction Logic (Lines 136-192): Converting text to predictions
Web Service Endpoints (Lines 194-470): Handling requests from users/applications

A) System Initialization (Lines 1-21)
What happens: The system prepares itself to run

Technical: Imports Flask framework, adds src/ directory to Python path, imports SwahiliPreprocessor
Non-technical: Like setting up a workspace - gathering all the tools needed before starting work
Global Variables: Creates placeholders for the AI model, feature extractor, and text preprocessor that will be used throughout the application

B) AI Model Management (Lines 22-134)
What it does: Decides which AI model to use and loads it into memory

Model Selection Strategy (Lines 22-30):

load_best_model(): Currently hardcoded to always choose BiLSTM
Why BiLSTM: It's the primary deployed model that performs best for Swahili scam detection
Non-technical analogy: Like choosing which expert consultant to hire for a specific job


BiLSTM Model Loading (Lines 61-125):

File loaded: models/bilstm_best_model.pth (the trained neural network)
What's inside the file:

Model weights (the "learned knowledge")
Vocabulary dictionary (all known Swahili words mapped to numbers)


BiLSTMWrapper Class (Lines 81-115): Creates a standardized interface

Purpose: Makes the BiLSTM model work the same way as other models
Key methods:

predict_proba(): Takes text, returns scam probability
text_to_sequence(): Converts Swahili words to numbers the model understands


Text Processing Flow: Raw text → SwahiliPreprocessor.preprocess() → word-to-number conversion → neural network → probability




Fallback Options (Lines 31-59, 127-131):

Traditional ML Models: Random Forest, SVM, Logistic Regression (requires models/best_model.pkl)
BERT Model: Google's advanced language model (placeholder for future implementation)
Smart Fallback: If BiLSTM fails to load, automatically tries traditional ML models



C) Prediction Logic (Lines 136-192)
What it does: The brain of the system that actually makes scam/legitimate decisions

Feature Extraction for Traditional ML (Lines 136-168):

When used: Only if traditional ML models are loaded (not BiLSTM)
Process:

Extracts linguistic features from the message
Loads training feature columns from data/processed/features.csv
Ensures new message has same feature structure as training data
Non-technical: Like filling out a standardized form with checkboxes for "contains phone number", "mentions money", etc.




Universal Prediction Function (Lines 170-192):

predict_message(): Works with any loaded model type
BiLSTM Path: Direct text input → preprocessing → neural network → probability
Traditional ML Path: Text → feature extraction → mathematical model → probability
Decision Logic: Scam if confidence > 50% (0.5 threshold)
Output: Returns (is_scam: boolean, confidence: float)



D) Web Service Endpoints (Lines 194-470)
What it provides: Four web addresses that external applications can access

Main Web Interface - GET / (Lines 194-363):

Purpose: User-friendly webpage for testing the system
What you see: Text box to enter Swahili message + "Check Message" button
Features:

Responsive Design: Works on desktop, tablet, and mobile phones
Real-time Results: Shows scam/safe classification with confidence percentage
Visual Feedback: Red background for scams, green for safe messages
Bilingual: Interface in both Swahili and English


Technical Implementation: Embedded HTML/CSS/JavaScript that calls the prediction API


Prediction API - POST /api/predict (Lines 365-399):

Purpose: The core service that other applications use to get predictions
Input Format: JSON {"message": "Hongera! Umeshinda..."}
Processing Flow:

Validates message is provided
Checks if AI model is loaded and ready
Calls predict_message() with the text
Formats response with detailed probabilities


Output Format:
json{
  "message": "original text",
  "is_scam": true/false,
  "confidence": 0.85,
  "scam_probability": 0.85,
  "safe_probability": 0.15,
  "model_type": "Bi-LSTM"
}

Error Handling: Returns appropriate error codes if something goes wrong


Health Check - GET /api/status (Lines 401-413):

Purpose: Allows monitoring systems to check if the service is working
Information provided:

Service status (running/stopped)
Whether AI model is loaded successfully
Which model type is currently active
System version number


Use case: DevOps teams use this to monitor system health in production


Testing Endpoint - GET /api/test (Lines 415-452):

Purpose: Automated testing with predefined Swahili messages
Test Messages Include:

Scam examples: "Hongera! Umeshinda TSH 1,000,000..."
Legitimate examples: "Habari za asubuhi. Mkutano wetu..."


Output: Batch predictions for all test messages
Use case: Developers use this to verify the system works after updates



E) Application Bootstrap (Lines 454-470)
What happens when you run the system:

Startup Message: Displays "🚀 Starting Swahili Scam Detection API..."
Model Loading: Attempts to load the AI model using load_model()
Success Path: If model loads successfully:

Displays success confirmation
Shows available URLs (http://localhost:5000)
Starts the Flask web server on port 5000


Failure Path: If model loading fails:

Shows error message
Suggests running model training first
Exits without starting the server



F) Key Design Principles

Universal Interface: Same prediction function works with different AI models
Graceful Degradation: Falls back to simpler models if advanced ones fail
Consistent Preprocessing: Same text cleaning for training and serving
Comprehensive API: Supports both human users (web UI) and applications (REST API)
Production Ready: Includes health monitoring, error handling, and testing endpoints

G) Real-World Usage Example
Scenario: A mobile app wants to check if a received SMS is a scam

App sends HTTP request: POST /api/predict with message text
Backend processes: Text → preprocessing → AI model → probability calculation
Response returned: JSON with scam classification and confidence score
App displays: Warning to user if scam probability > 50%

Technical Notes:

Confidence Threshold: Default 0.5 (50%) can be adjusted in predict_message() for different precision/recall trade-offs
Model Consistency: Same SwahiliPreprocessor used in training and serving ensures consistent text handling
Memory Management: Models loaded once at startup, kept in memory for fast predictions
Cross-Origin Support: CORS enabled for web applications from different domains

3. ANSWERS TO REVIEWER QUESTIONS
Q 6/33 — Model results were presented without background.
Background outline:

Data: data/raw/swahili_messages_sample.csv (constructed by data/sample_data.py → create_sample_dataset(), save_dataset())
Preprocessing: src/swahili_preprocessor.py (clean_text, normalize_slang, remove_stopwords)
Features (traditional ML): src/feature_extractor.py (TF-IDF + linguistic features; saved to data/processed/)
Models: BiLSTM with attention (src/bilstm_model.py), BERT fine-tuning (src/bert_model.py)
Evaluation: accuracy/precision/recall/F1 reported by respective trainers
Serving: api/app.py exposes /api/predict and a test UI at /

Q 6/40 — How Swahili stop/slang words were identified and used. Any lemmatization?

Stopwords: Curated list in SwahiliPreprocessor.__init__() → swahili_stopwords
Slang/variants: slang_dict maps common variants to canonical forms (e.g., doo/hela/cash → pesa) processed by normalize_slang() with word-boundary regex
Lexicons: scam_keywords, urgency_words, money_terms, emotion_words support both feature extraction and qualitative robustness
Lemmatization: Not used. Pipeline relies on normalization + stopword removal + tokenization; this is stated as a limitation and future work due to scarce robust Swahili lemmatizers

Q 7/41 — Which Swahili tokenizers were used?

BERT: Hugging Face AutoTokenizer for bert-base-multilingual-cased (src/bert_model.py), chosen for multilingual subword coverage and compatibility
BiLSTM: Custom tokenizer: SwahiliPreprocessor.preprocess() → regex clean → corpus-derived vocabulary (build_vocabulary()) → text_to_sequence() (src/bilstm_model.py). Justification: tight coupling to dataset vocabulary and low-resource constraints

Q 8/54 — Explain code in section 6.4 (Flask backend).
See Section 6.4 explanation above (api/app.py): model loading, endpoints, prediction flow, example response, and design notes.
Q 9/55 — Provide at least one screenshot of the mobile app.
The project provides a responsive web UI via Flask (api/app.py, route /). To capture a mobile-like screenshot:

Run: python api/app.py (starts http://localhost:5000)
Open in Chrome → F12 → Toggle Device Toolbar → choose a phone profile (e.g., Pixel 7) → enter a sample message → click "Check Message"
Take a screenshot showing the input and the classification result
If you have open the url in a mobile device browser, screenshot from there

Q 10/61 — How results addressed objectives.
Objective (a): Analyze linguistic characteristics.

Implemented via custom features and lexicons in src/feature_extractor.py and src/swahili_preprocessor.py: counts of phone numbers, money expressions, congratulatory/time-pressure/action words; scam/urgency/money/emotion signals; language-mix detection
analyze_features() reports top correlated features with the scam label

Objective (b): Develop a Kiswahili scam detector.

BiLSTMClassifier with attention (src/bilstm_model.py) trained by SwahiliBiLSTMTrainer; BERT fine-tuning option (src/bert_model.py)
Serving-ready API (api/app.py) enabling real-time classification and confidence scores

Objective (c): Evaluate performance using accuracy and other metrics.

BiLSTM: evaluate_model() computes accuracy, precision, recall, F1 on held-out test set; prints "FINAL BI-LSTM RESULTS"
BERT: compute_metrics() returns accuracy, precision, recall, F1 via Trainer.evaluate()

Objective (d): Construct and annotate a Swahili dataset.

data/sample_data.py programmatically constructs labeled examples across scam categories (lottery/prize, mobile money, emergency/family, investment/business, govt/authority) and legitimate messages with metadata (message_id, label, category, source, date_collected, language)
save_dataset() persists CSV to data/raw/; analyze_dataset() prints summary stats and sample messages

Q 11/65 — Duplicate references (2, 7, 14).
Resolution guidance: In your thesis toolchain (Word/Zotero/LaTeX), merge duplicates and re-number. Ensure unique keys (LaTeX) and recompile to refresh numbering.
Q 12 — Thesis ordering should follow standard ML workflow.
Recommended structure:

Problem & Objectives
Related Work
Data Collection & Description (data/raw/, sample_data.py)
Preprocessing & Lexicons (src/swahili_preprocessor.py)
Feature Engineering (src/feature_extractor.py)
Models (src/bilstm_model.py, src/bert_model.py)
Training & Evaluation Protocol
Results & Analysis
Deployment (api/app.py)
Limitations & Future Work
Conclusion

4. PRACTICAL NOTES AND TIPS
Reproducible training

BiLSTM: run python src/bilstm_model.py → saves models/bilstm_best_model.pth and models/bilstm_model.pth plus models/bilstm_vocab.pkl
BERT: run python src/bert_model.py → saves models/bert_model and models/bert_tokenizer

API usage

Start: python api/app.py → /api/status should show model_type = Bi-LSTM if checkpoint exists
Predict: curl -X POST http://localhost:5000/api/predict -H "Content-Type: application/json" -d '{"message": "..."}'

Adjusting threshold

Default classification uses confidence > 0.5 for scam. You can adjust this in api/app.py → predict_message() to trade off precision/recall

Dataset size/representativeness: sample dataset is synthetic/curated; future expansion with real-world, ethically collected and anonymized messages is recommended

5. SUMMARY FOR SLIDES
    Data Collection: Constructed a labeled dataset for Kiswahili scam messages, with the creation script located at data/sample_data.py and the raw data stored in the data/raw/ directory.

    Linguistic Processing: Designed specialized Swahili natural language processing components, including:
      > A dedicated preprocessor (src/swahili_preprocessor.py) to handle slang normalization and code-switching.
      > A feature extractor (src/feature_extractor.py) to engineer relevant linguistic features.

    Model Training: Developed and trained multiple deep learning models for comparison:
      > A custom BiLSTM with an attention mechanism (src/bilstm_model.py).
      > A strong baseline using multilingual BERT (src/bert_model.py).

    Deployment & Evaluation:
      > Deployed the final model as a live inference API (api/app.py).
      > Built a responsive web interface that works on both desktop and mobile devices for public use.
      > Rigorously evaluated all models on a held-out test set, reporting standard metrics: accuracy, precision, recall, and F1-score.
      > The system provides users with interpretable confidence scores for each prediction.
      
6. DETAILED Q&A WITH CODE REFERENCES (FILES • METHODS • LINE NUMBERS)
Q1. Where is the dataset created and saved?

File: data/sample_data.py
Create: create_sample_dataset() at lines 6–1120 (full construction of messages; returns DataFrame at line 1120)
Save: save_dataset(df, filename) at lines 1122–1127 (writes to data/raw/<filename>)
Output CSV: data/raw/swahili_messages_sample.csv

Q2. What exactly happens during text preprocessing?

File: src/swahili_preprocessor.py
Class: SwahiliPreprocessor at line 6
Stopwords/slang/lexicons defined in __init__() at lines 7–51
clean_text() at lines 53–76: lowercasing, remove URLs/emails/phone numbers, keep letters, collapse spaces
normalize_slang() at lines 78–85: maps variants to canonical forms using slang_dict
remove_stopwords() at lines 87–91
preprocess() at lines 111–122: calls clean_text → normalize_slang → remove_stopwords
extract_basic_features() at lines 124–155: text stats, scam/urgency/money/emotion counts, punctuation, language-mix

Q3. How are traditional ML features built and saved?

File: src/feature_extractor.py
Class: SwahiliFeatureExtractor at line 13
TF-IDF setup in __init__() at lines 14–22
Linguistic features: extract_linguistic_features(text) at lines 24–56 (phone numbers lines 35–39, money patterns lines 40–43, action words lines 44–47, congratulatory lines 48–51, time pressure lines 52–55)
Pipeline: prepare_features(df) at lines 62–101 (preprocess at line 67; TF-IDF at lines 79–89; combine and name features at lines 81–99)
Save outputs: load_and_process_data() at lines 131–167 writes data/processed/features.csv and labels.csv (write: lines 160–161; print: 163–164)

Q4. How does the BiLSTM tokenize and make predictions?

File: src/bilstm_model.py
Dataset tokenization: SwahiliTextDataset.text_to_sequence() at lines 37–58 uses SwahiliPreprocessor.preprocess() (line 39) and regex to keep word/number tokens
Model: BiLSTMClassifier defined at lines 60–105 with attention at line 78 and classifier head at lines 81–84
Training loop: SwahiliBiLSTMTrainer.train_model() at lines 151–274 with early stopping checkpoint saved at lines 234–240 to models/bilstm_best_model.pth
Evaluation: evaluate_model() at lines 275–304

Q5. Which model is loaded in the API and how is text turned into inputs?

File: api/app.py
Default load: load_best_model() at lines 22–30 → load_bilstm_model() at lines 61–125
Wrapper: inner BiLSTMWrapper at lines 81–115

Preprocess and predict: predict_proba(self, X) at lines 87–101 uses SwahiliPreprocessor.preprocess() at line 91
Sequence conversion: text_to_sequence() at lines 102–113 pads/truncates to max_length=128


Fallback to traditional ML: load_traditional_model() at lines 31–59

Q6. What happens inside the prediction endpoint and decision threshold?

File: api/app.py
Universal prediction: predict_message(message) at lines 170–192

If BiLSTM (feature_extractor is None): model.predict_proba([message]) at line 175, confidence is scam probability at line 176
Threshold: scam if confidence > 0.5 at line 177 (adjust here to change sensitivity)


Endpoint: @app.route('/api/predict') handler predict_scam() at lines 365–400; returns JSON with is_scam, confidence, and probabilities at lines 386–394

Q7. Where is the mobile-friendly UI and how do I preview it?

File: api/app.py
Route: @app.route('/') function home() at lines 194–364; returns embedded HTML/CSS/JS
How to run: python api/app.py then open http://localhost:5000 (see lines 454–467 for startup logs)

Q8. How are BERT tokenizer and model configured?

File: src/bert_model.py
Tokenizer/model init: initialize_model() at lines 54–65 using bert-base-multilingual-cased
Datasets: SwahiliBERTDataset at lines 10–37
Training: train_model() at lines 78–130 with TrainingArguments at lines 90–101 and evaluation/report at lines 113–121

Q9. How does language-mix detection work?

File: src/swahili_preprocessor.py
Method: detect_language_mix(text) at lines 93–109; computes English/Swahili word ratios and mixed_language boolean
Used in: extract_basic_features() updates these keys at lines 151–153

Q10. Where are processed features/labels used by the API's traditional path?

File: api/app.py
Feature construction for single prediction: extract_features_for_prediction(message) at lines 136–168
Loads training columns from data/processed/features.csv at lines 147–163 to align columns before calling model.predict_proba

Q11. Where can I change max input length for the BiLSTM?

Files: api/app.py and src/bilstm_model.py
Inference wrapper: BiLSTMWrapper.text_to_sequence(..., max_length=128) at lines 102–113 of api/app.py
Dataset side: SwahiliTextDataset.__init__(..., max_length=128) at lines 21–26 and padding logic in text_to_sequence() at lines 55–58 of src/bilstm_model.py

Q12. How are evaluation metrics computed and reported?

BiLSTM: evaluate_model() at lines 275–304 of src/bilstm_model.py computes Accuracy/Precision/Recall/F1 (weighted)
BERT: compute_metrics() at lines 66–76 of src/bert_model.py and printed in train_model() at lines 113–121

NOTES ON LINE NUMBERS
Line numbers refer to the versions in this repository as of this documentation edit. If you modify files, search by function/class names to locate the exact blocks again.